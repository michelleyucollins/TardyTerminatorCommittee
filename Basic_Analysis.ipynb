{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_prefix = \"./data/delays/ttc-bus-delay-data-\"\n",
    "file_names = []\n",
    "for i in range(2016, 2025):\n",
    "    file_names.append(f\"{bus_prefix}{i}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_sheets_to_csv(file_names, output_csv=\"combined.csv\"):\n",
    "    \"\"\"\n",
    "    Reads all sheets from every Excel file in file_names (without interpreting any row as header),\n",
    "    concatenates the data from all sheets vertically, and exports the combined data to a CSV file\n",
    "    without any column headers.\n",
    "\n",
    "    Parameters:\n",
    "        file_names (list of str): List of paths to Excel files.\n",
    "        output_csv (str): The path for the output CSV file.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    column_data = ['Report Date','Route','Time','Day','Location','Incident', 'Min Delay','Min Gap','Direction','Vehicle']\n",
    "\n",
    "    for file in file_names:\n",
    "        # Open the excel sheet\n",
    "        try:\n",
    "            excel_file = pd.ExcelFile(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening file '{file}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # Read and append values for each sheet in the file\n",
    "        for sheet in excel_file.sheet_names:\n",
    "            try:\n",
    "                # Header is first row\n",
    "                dummy = pd.read_excel(excel_file, sheet_name=sheet, header=0)\n",
    "                dummy.columns = column_data\n",
    "                all_data.append(dummy)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading sheet '{sheet}' in file '{file}': {e}\")\n",
    "                continue\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"There was no data in any file given or the passed file_name vector was empty\")\n",
    "        return\n",
    "\n",
    "    # Concat all the data vertically\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df.columns = column_data\n",
    "\n",
    "    try:\n",
    "        # Export to CSV without column headers and without the index.\n",
    "        combined_df.to_csv(output_csv, header=column_data, index=False)\n",
    "        print(f\"Combined data successfully exported to '{output_csv}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting data to CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data successfully exported to './data/delays/bus-delay-data-2016-2024.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Combine all sheets to csv file and process the csv file\n",
    "combine_all_sheets_to_csv(file_names, output_csv=\"./data/delays/bus-delay-data-2016-2024.csv\")\n",
    "# !!!!!!!!!!!!!!!!!!DATE TIME PROCESSING MUST BE DONE LOCALLY IN EXCEL THIS NEARLY CRASHED MY COMPUTER!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_full_ttc_csv(file_name): \n",
    "    '''\n",
    "    Function for processing TTC delay data stored in a CSV file. This function must be run prior to further analysis to allow for some\n",
    "    functions to run smoothly.\n",
    "    Manual grunt work may be needed for certain data cleaning, which is why print statements are added for some brief manual parsing\n",
    "\n",
    "    Input: file name of a TTC Delay CSV File\n",
    "    Output: returns a dictionary of data for the specified file_name (unique categoricies for a feature, etc)\n",
    "    '''\n",
    "    column_data = ['DateTime','Report Date','Route','Time','Day','Location','Incident', 'Min Delay','Min Gap','Direction','Vehicle']\n",
    "    df = pd.read_csv(file_name)\n",
    "    for col in column_data:\n",
    "        df[col] = df[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "        if isinstance(df[col][1], str):\n",
    "            print(df[col].unique)\n",
    "    \n",
    "    df.to_csv(file_name, index='DateTime')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xt/5my4_t657l5dvcsk9ybkb_ww0000gn/T/ipykernel_31598/3709269345.py:11: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_name)\n"
     ]
    }
   ],
   "source": [
    "pre_processing_full_ttc_csv(\"./data/delays/bus-delay-final copy.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
