{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import json\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_prefix = \"./data/delays/ttc-bus-delay-data-\"\n",
    "file_names = []\n",
    "for i in range(2016, 2025):\n",
    "    file_names.append(f\"{bus_prefix}{i}.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_all_sheets_to_csv(file_names, output_csv=\"combined.csv\"):\n",
    "    \"\"\"\n",
    "    Reads all sheets from every Excel file in file_names (without interpreting any row as header),\n",
    "    concatenates the data from all sheets vertically, and exports the combined data to a CSV file\n",
    "    without any column headers.\n",
    "\n",
    "    Parameters:\n",
    "        file_names (list of str): List of paths to Excel files.\n",
    "        output_csv (str): The path for the output CSV file.\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "\n",
    "    column_data = ['Report Date','Route','Time','Day','Location','Incident', 'Min Delay','Min Gap','Direction','Vehicle']\n",
    "\n",
    "    for file in file_names:\n",
    "        # Open the excel sheet\n",
    "        try:\n",
    "            excel_file = pd.ExcelFile(file)\n",
    "        except Exception as e:\n",
    "            print(f\"Error opening file '{file}': {e}\")\n",
    "            continue\n",
    "\n",
    "        # Read and append values for each sheet in the file\n",
    "        for sheet in excel_file.sheet_names:\n",
    "            try:\n",
    "                # Header is first row\n",
    "                dummy = pd.read_excel(excel_file, sheet_name=sheet, header=0)\n",
    "                dummy.columns = column_data\n",
    "                all_data.append(dummy)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading sheet '{sheet}' in file '{file}': {e}\")\n",
    "                continue\n",
    "\n",
    "    if not all_data:\n",
    "        print(\"There was no data in any file given or the passed file_name vector was empty\")\n",
    "        return\n",
    "\n",
    "    # Concat all the data vertically\n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "    combined_df.columns = column_data\n",
    "\n",
    "    try:\n",
    "        # Export to CSV without column headers and without the index.\n",
    "        combined_df.to_csv(output_csv, header=column_data, index=False)\n",
    "        print(f\"Combined data successfully exported to '{output_csv}'.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error exporting data to CSV: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all sheets to csv file and process the csv file\n",
    "combine_all_sheets_to_csv(file_names, output_csv=\"./data/delays/bus-delay-data-2016-2024.csv\")\n",
    "# !!!!!!!!!!!!!!!!!!DATE TIME PROCESSING MUST BE DONE LOCALLY IN EXCEL THIS NEARLY CRASHED MY COMPUTER!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing_full_ttc_csv(file_name, dict_file_name = \"info.json\"): \n",
    "    '''\n",
    "    Function for processing TTC delay data stored in a CSV file. This function must be run prior to further analysis to allow for some\n",
    "    functions to run smoothly.\n",
    "    Manual grunt work may be needed for certain data cleaning, which is why print statements are added for some brief manual parsing\n",
    "\n",
    "    Input: file name of a TTC Delay CSV File; (optional) file name of a data_dict dump file, if empty it is defaulted to 'info.json'\n",
    "    Output: returns a dictionary of data for the specified file_name (unique categoricies for a feature, etc)\n",
    "\n",
    "    Note: the Data Dictionary is also stored as a JSON file for later use if needed\n",
    "    '''\n",
    "    df = pd.read_csv(file_name)\n",
    "    column_data = df.columns\n",
    "    data_dict = {}\n",
    "    for col in column_data:\n",
    "        df[col] = df[col].apply(lambda x: x.lower() if isinstance(x, str) else x)\n",
    "        if isinstance(df[col][1], str) and col != 'DateTime' and col != 'Report Date' and col != 'Time' and col != 'Day':\n",
    "            data_dict[col] = df[col].unique().tolist()\n",
    "            print(data_dict[col])\n",
    "    \n",
    "    df.to_csv(file_name, index='DateTime')\n",
    "    \n",
    "    with open(dict_file_name, \"w\") as outfile: \n",
    "        json.dump(data_dict, outfile)\n",
    "        \n",
    "    return data_dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m data_dict \u001b[38;5;241m=\u001b[39m \u001b[43mpre_processing_full_ttc_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/delays/bus-delay-final.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdict_file_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./data/delays/bus-delay-data.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 12\u001b[0m, in \u001b[0;36mpre_processing_full_ttc_csv\u001b[0;34m(file_name, dict_file_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpre_processing_full_ttc_csv\u001b[39m(file_name, dict_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo.json\u001b[39m\u001b[38;5;124m\"\u001b[39m): \n\u001b[1;32m      2\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m    Function for processing TTC delay data stored in a CSV file. This function must be run prior to further analysis to allow for some\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m    functions to run smoothly.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;124;03m    Note: the Data Dictionary is also stored as a JSON file for later use if needed\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241m.\u001b[39mread_csv(file_name)\n\u001b[1;32m     13\u001b[0m     column_data \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[1;32m     14\u001b[0m     data_dict \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "data_dict = pre_processing_full_ttc_csv(\"./data/delays/bus-delay-final.csv\", dict_file_name= \"./data/delays/bus-delay-data.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "colab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
